{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Train/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw = pd.read_csv('./data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_pickle('train.pkl')\n",
    "test_df = pd.read_pickle('test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df= train_df.drop('SalePrice', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 23)"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_dummies = [x for x in train_df.columns if not '_' in x ]\n",
    "train_df[non_dummies].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = train_df.drop(\n",
    "#     'PoolArea', axis=1) # mostly 0 and coleniar with 3SsnPorch and there is a binary for poolquality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary for 3SsnPorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['3SsnPorch'] = train_df['3SsnPorch'].isna().apply(lambda x: int(not x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_dummies_remove_modes(dummy_list, df_raw, df):\n",
    "    \"\"\" \n",
    "    add_dummies_remove_modes (dummy_list, df_raw, df)\n",
    "    takes a list of column names `dummy_list` to dummify then drop \n",
    "    after dummification, a reference dataframe `df_raw` to search for \n",
    "    the dominant value of each varable in `dummy_list` then drop the \n",
    "    dominant dummy variable and a dataframe `df` you wish to concat \n",
    "    dummified variables to.\n",
    "    \"\"\"\n",
    "\n",
    "    dummy_modes = list(df_raw[dummy_list].mode().iloc[0,:].items())\n",
    "\n",
    "    dummy_modes = [(col, (float(mode))) \n",
    "                   if type(mode) == int else (col, mode) for col, mode in dummy_modes]\n",
    "\n",
    "    drop_modes = list(map(lambda x: str(x[0]) + '_' + str(x[1]), dummy_modes))\n",
    "\n",
    "    dummy_cols = pd.get_dummies(\n",
    "        df[dummy_list].astype(object), dummy_na=True).drop(drop_modes, axis=1)\n",
    "\n",
    "    return pd.concat([\n",
    "       df.drop(dummy_list, axis=1),\n",
    "       dummy_cols], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dates = ['YearBuilt', 'YearRemodAdd', 'GarageYrBlt', 'MoSold', 'YrSold']\n",
    "# train_df[dates].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change remodled year to years since remodeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['YearRemodAdd']  = (2010 - train_df['YearRemodAdd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['YearRemodAdd']  = (2010 - test_df['YearRemodAdd'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bin years then dummifying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yb = train_df['YearBuilt']\n",
    "\n",
    "range_bins = [(1800,1900), (1900,1910), (1910,1920), (1920,1930), (1930,1940), (1940,1950), (1950,1960), (1960,1970), (1970,1980), (1980,1990), (1990,2000), (2000,2011)]\n",
    "\n",
    "bins = {r:x for (x,y) in range_bins for r in range(x,y)}\n",
    "\n",
    "train_df = pd.concat([train_df.drop('YearBuilt', axis=1), Yb.map(bins)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yb = test_df['YearBuilt']\n",
    "test_df = pd.concat([test_df.drop('YearBuilt', axis=1), Yb.map(bins)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Year to Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df[['YearBuilt']] = train_df[['YearBuilt']].apply(lambda x: x.max() - x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df[['YearBuilt']] = test_df[['YearBuilt']].apply(lambda x: x.max() - x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummify MoSold and YrSold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = add_dummies_remove_modes(['MoSold', 'YrSold'], train_df, train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gavagai/.conda/envs/data_science/lib/python3.6/site-packages/sklearn/preprocessing/data.py:617: DataConversionWarning: Data with input dtype object were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/gavagai/.conda/envs/data_science/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype object were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "cont = train_df.T[np.array(train_df.nunique() > 80)].T.columns.delete(-1)\n",
    "scale = StandardScaler()\n",
    "train_df[cont] = scale.fit_transform(train_df[cont])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gavagai/.conda/envs/data_science/lib/python3.6/site-packages/sklearn/preprocessing/data.py:617: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/gavagai/.conda/envs/data_science/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "cont = test_df.T[np.array(test_df.nunique() > 80)].T.columns.delete(-1)\n",
    "scale = StandardScaler()\n",
    "test_df[cont] = scale.fit_transform(test_df[cont])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reorder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df[train_df.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add SalePrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['SalePrice'] = train_raw['SalePrice']#.apply(lambda x: np.log(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_pickle('train_engineered.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_pickle('test_engineered.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
